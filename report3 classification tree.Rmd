---
title: "R Notebook"
output:
  html_document:
    df_print: paged
---
```{r }
library(tidyverse) 
library(ggplot2) 
library(Rserve)
library(mvoutlier)
library(car)
library(lmtest)
library(sandwich)
library(forecast)
library(leaps)
library(gains)
library(caret)
library(ggplot2)
library(rpart)
library(rpart.plot)

```


```{r}
movie.t <- read.csv('/Users/blue/Desktop/Bigdata2/joindata2.csv')
movie.t$popularmovie <- ifelse(movie.t$averageRating > 6.37,1,0)
set.seed(2)
# select variables for regression
selected.var <- c(3,6,15,19,20)   
train.index <- sample(c(1:dim(movie.t)[1]), dim(movie.t)[1]*0.6) 
#partition data into training set and validation set in 6:4
train.df <- movie.t[ train.index, selected.var]
valid.df <- movie.t[ -train.index, selected.var]
```
```{r}

default.ct1 <- rpart(popularmovie ~ ., data = train.df, method = "class", 
                    control = rpart.control(maxdepth = 5))
# plot tree
prp(default.ct1, type = 1, extra = 1, under = TRUE, split.font = 1, varlen = -10)


```

```{r}
#instead of controlling by depth, control by cp (cost of complexity penalty)
deeper.ct <- rpart(popularmovie ~ ., data = train.df, method = "class", 
                   cp = 0, minsplit = 1) #no penalty for complexity
# count number of leaves
length(deeper.ct$frame$var[deeper.ct$frame$var == "<leaf>"])

# plot tree
prp(deeper.ct, type = 1, extra = 1, under = TRUE, split.font = 1, varlen = -10, 
    box.col=ifelse(deeper.ct$frame$var == "<leaf>", 'gray', 'white'))  
```
```{r train part}
deeper.ct.point.pred.train <- predict(deeper.ct, train.df,type = "class")
confusionMatrix( deeper.ct.point.pred.train, as.factor(train.df$popularmovie))

default.ct.point.pred.train <- predict( default.ct1, train.df,type = "class")
confusionMatrix( default.ct.point.pred.train, as.factor(train.df$popularmovie))

```


```{r validation part}
default.ct.point.pred.valid <- predict( default.ct1, valid.df, type = "class")
confusionMatrix( default.ct.point.pred.valid, as.factor(valid.df$popularmovie))
#overfitting
deeper.ct.point.pred.valid <- predict( deeper.ct, valid.df, type = "class")
confusionMatrix( deeper.ct.point.pred.valid, as.factor(valid.df$popularmovie) )


```
```{r}
curr_F1 <- 0  # worst F1 possible; we can do better than that, can't we?
best_cost_penalty <- 0
best_min_leaf_to_split <- 2

for( cost_penalty in seq(from=0, to=0.1, by=0.01)) {
  for( min_leaf_to_split in seq(from=1, to=10, by=1)) {
    
    # train the tree
    trained_tree <- rpart(popularmovie ~ ., data = train.df, method = "class", 
                          cp = cost_penalty, minsplit = min_leaf_to_split)
    
    # predict with the trained tree
    train.results <- predict( trained_tree, train.df, type = "class" )
    valid.results <- predict( trained_tree, valid.df, type = "class" )  
    
    # generate the confusion matrix to compare the prediction with the actual value of Personal Loan acceptance (0/1), 
    # to calculate the sensitivity and specificity
    results <- confusionMatrix( valid.results, as.factor(valid.df$popularmovie) )
    
    # calculate F1 from results
    Sensitivity <- results$byClass[1] # where did this come from?
    Specificity <- results$byClass[2] 
    F1 <- (2 * Sensitivity * Specificity) / (Sensitivity + Specificity)
    
    # Is this F1 the best we have so far? If so, store the current values:
    if( F1 > curr_F1 ) {
      curr_F1 <- F1
      best_cost_penalty <- cost_penalty
      best_min_leaf_to_split <- min_leaf_to_split
    }
  }
}
cat("best F1=" , curr_F1, "; best best_cost_penalty=", best_cost_penalty, "; best_min_leaf_to_split=", best_min_leaf_to_split)

# retrain the tree to match the best parameters we found  
trained_tree <- rpart(popularmovie ~ ., data = train.df, method = "class", 
                      cp = best_cost_penalty , minsplit = best_min_leaf_to_split )  # change the original parameters

# print that best tree 
prp(trained_tree, type = 1, extra = 1, under = TRUE, split.font = 1, varlen = -10, 
    box.col=ifelse(trained_tree$frame$var == "<leaf>", 'gray', 'white'))  

```
```{r confusion matrix for grid}
gridsearch..pred.train <- predict(trained_tree, train.df,type = "class")
confusionMatrix(gridsearch..pred.train , as.factor(train.df$popularmovie))
gridsearch..pred.valid <- predict(trained_tree, valid.df,type = "class")
confusionMatrix(gridsearch..pred.valid , as.factor(valid.df$popularmovie))
```

```{r}
# argument cp sets the smallest value for the complexity parameter.
cv.ct <- rpart(popularmovie ~ ., data = train.df, method = "class", 
               cp = 0, minsplit = 3, xval = 5)
# use printcp() to print the table. 
prp(cv.ct)
printcp(cv.ct)
# best model:7  0.00685871     13  0.533608 0.63923 0.025005
# or should we keep pruning it?
```

#### Figure 9.12
```{r}
# prune by minimum cp, calling the prune function
pruned.ct <- prune(cv.ct, 
                   cp = cv.ct$cptable[which.min(cv.ct$cptable[,"xerror"]),"CP"])
length(pruned.ct$frame$var[pruned.ct$frame$var == "<leaf>"])
prp(pruned.ct, type = 1, extra = 1, split.font = 1, varlen = -10)  

# that one looks better, more interpretable, balanced, pruned a bit more
printcp(pruned.ct)
```
```{r confusion matrix for auto way}
prune.pred.train <- predict(pruned.ct, train.df,type = "class")
confusionMatrix(prune.pred.train , as.factor(train.df$popularmovie))

prune.pred.valid <- predict(pruned.ct, valid.df,type = "class")
confusionMatrix(prune.pred.valid , as.factor(valid.df$popularmovie))
```
```{r cross validation}
cv.ct <- rpart(popularmovie ~ ., data = train.df, method = "class", cp = 0.001, minsplit = 1, xval = 5)  # minsplit is the minimum number of observations in a node for a split to be attempted. xval is number K of folds in a K-fold cross-validation.
printcp(cv.ct)  # Print out the cp table of cross-validation errors. The R-squared for a regression tree is 1 minus rel error. xerror (or relative cross-validation error where "x" stands for "cross") is a scaled version of overall average of the 5 out-of-sample errors across the 5 folds.
```

```{r}
pruned.ct2 <- prune(cv.ct, cp = 0.0059442)
printcp(pruned.ct2)
options(scipen=999)

prp(pruned.ct2, type = 1, extra = 1, under = TRUE, split.font = 1, varlen = -10, digits=-3,
    box.col=ifelse(pruned.ct$frame$var == "<leaf>", 'gray', 'white')) 
## variable importance plot
#summary(pruned.ct2)

```
```{r}
prune.pred.train2 <- predict(pruned.ct2, train.df,type = "class")
confusionMatrix(prune.pred.train2 , as.factor(train.df$popularmovie))

prune.pred.valid2 <- predict(pruned.ct2, valid.df,type = "class")
confusionMatrix(prune.pred.valid2 , as.factor(valid.df$popularmovie))
```

```{r}
pruned.ct3 <- prune(cv.ct, cp = 0.0082305)
prp(pruned.ct3, type = 1, extra = 1, under = TRUE, split.font = 1, varlen = -10, 
    box.col=ifelse(pruned.ct$frame$var == "<leaf>", 'gray', 'white')) 
```
```{r}
prune.pred.train3 <- predict(pruned.ct3, train.df,type = "class")
confusionMatrix(prune.pred.train3 , as.factor(train.df$popularmovie))

prune.pred.valid3 <- predict(pruned.ct3, valid.df,type = "class")
confusionMatrix(prune.pred.valid , as.factor(valid.df$popularmovie))


```